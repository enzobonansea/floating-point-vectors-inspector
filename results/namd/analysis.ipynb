{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "444a2c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines: 100%|██████████| 1137625979/1137625979 [1:38:20<00:00, 192817.23line/s] \n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_memlog_in_chunks(file_path):\n",
    "    stores_file = open('stores.csv', 'w', newline='')\n",
    "    allocation_sites_file = open('allocation_sites.csv', 'w', newline='')\n",
    "\n",
    "    stores_writer = csv.writer(stores_file)\n",
    "    allocation_sites_writer = csv.writer(allocation_sites_file)\n",
    "\n",
    "    # Write header for the CSV files\n",
    "    stores_writer.writerow(['address', 'value'])\n",
    "    allocation_sites_writer.writerow(['start', 'size', 'stack_trace'])\n",
    "\n",
    "    store_started = False\n",
    "    allocation_started = False\n",
    "    allocation_sites = []\n",
    "    stack_trace = []\n",
    "\n",
    "    # Open the file and count the total number of lines for tqdm\n",
    "    with open(file_path, 'r') as f:\n",
    "        total_lines = sum(1 for line in f)  # Count total lines in the file\n",
    "        f.seek(0)  # Rewind the file to start processing\n",
    "\n",
    "        # Create a tqdm progress bar for line processing\n",
    "        for line in tqdm(f, total=total_lines, desc=\"Processing lines\", unit=\"line\"):\n",
    "            # Skip lines before \"Parent PID\" and the following line\n",
    "            if 'Parent PID' in line:\n",
    "                store_started = True\n",
    "                continue\n",
    "            elif store_started and line.strip() == '':\n",
    "                continue\n",
    "\n",
    "            # Process store lines\n",
    "            if store_started and not allocation_started:\n",
    "                # Ignore the line after the line containing 'Parent PID'\n",
    "                if len(line.strip().split()) == 1:\n",
    "                    continue\n",
    "\n",
    "                # Look for the \"=== Allocation sites ===\" line\n",
    "                if line.strip() == '=== Allocation sites ===':\n",
    "                    allocation_started = True\n",
    "                    continue\n",
    "\n",
    "                # Process store lines: <address> <value>\n",
    "                if line.strip():\n",
    "                    address, value = line.split()\n",
    "                    stores_writer.writerow([address, value])\n",
    "\n",
    "            # Process allocation site lines\n",
    "            if allocation_started:\n",
    "                if line.strip():\n",
    "                    if line.startswith('Start'):\n",
    "                        # Capture the start and size from the allocation site line\n",
    "                        start, size = line.split(',')[0].split()[1], line.split(',')[1].split()[1]\n",
    "                        # If there's already a previous allocation site, write it before starting a new one\n",
    "                        if allocation_sites:\n",
    "                            allocation_sites_writer.writerow([allocation_sites[0], allocation_sites[1], ' '.join(allocation_sites[2])])\n",
    "                        # Start a new allocation site\n",
    "                        allocation_sites = [start, size, []]\n",
    "                    else:\n",
    "                        # Add stack trace line for the current allocation site\n",
    "                        allocation_sites[2].append(line.strip())\n",
    "\n",
    "    # After finishing the file, write any remaining allocation site\n",
    "    if allocation_sites:\n",
    "        allocation_sites_writer.writerow([allocation_sites[0], allocation_sites[1], ' '.join(allocation_sites[2])])\n",
    "\n",
    "    # Close CSV files\n",
    "    stores_file.close()\n",
    "    allocation_sites_file.close()\n",
    "\n",
    "# Example usage\n",
    "process_memlog_in_chunks('memlog.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9ee83e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading allocation sites...\n",
      "Total allocation sites loaded: 2210\n",
      "Counting total lines in stores.csv for progress tracking...\n",
      "Processing stores.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing stores: 100%|██████████| 1137609478/1137609478 [21:04:44<00:00, 14991.35store/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing analysis results to CSV...\n",
      "Analysis complete. Results saved to allocation_analysis.csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from tqdm import tqdm\n",
    "import bisect\n",
    "import struct\n",
    "\n",
    "def hex_to_double(hex_str):\n",
    "    \"\"\"\n",
    "    Convert a hexadecimal string to a double-precision floating-point number.\n",
    "    \n",
    "    Parameters:\n",
    "        hex_str (str): Hexadecimal string representing the double (e.g., '0x3f9c71c71c71c71c').\n",
    "    \n",
    "    Returns:\n",
    "        float: The corresponding double value.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Remove '0x' prefix if present\n",
    "        hex_str = hex_str.lower().replace('0x', '')\n",
    "        # Ensure the hex string has exactly 16 characters (8 bytes)\n",
    "        hex_str = hex_str.zfill(16)\n",
    "        # Convert hex string to bytes\n",
    "        byte_data = bytes.fromhex(hex_str)\n",
    "        # Unpack bytes to double (big-endian)\n",
    "        double_val = struct.unpack('>d', byte_data)[0]\n",
    "        return double_val\n",
    "    except (ValueError, struct.error) as e:\n",
    "        print(f\"Error converting hex to double for '{hex_str}': {e}\")\n",
    "        return None\n",
    "\n",
    "def hex_to_int(hex_str):\n",
    "    \"\"\"\n",
    "    Convert a hexadecimal string to an integer.\n",
    "    \n",
    "    Parameters:\n",
    "        hex_str (str): Hexadecimal string (e.g., '0x4f990d8').\n",
    "    \n",
    "    Returns:\n",
    "        int: The corresponding integer value.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(hex_str, 16)\n",
    "    except ValueError:\n",
    "        print(f\"Invalid hexadecimal address: {hex_str}\")\n",
    "        return None\n",
    "\n",
    "def load_allocation_sites(allocation_sites_csv):\n",
    "    \"\"\"\n",
    "    Load allocation sites from CSV into a sorted list.\n",
    "    \n",
    "    Each allocation site is a dictionary containing:\n",
    "        - start: Start address (int)\n",
    "        - end: End address (int)\n",
    "        - size: Size (int)\n",
    "        - stack_trace: Stack trace (str)\n",
    "        - total_stores: Total number of stores (int)\n",
    "        - zero_values: Number of stores with value 0.0 (int)\n",
    "        - max_value: Maximum store value (float)\n",
    "        - min_value: Minimum store value (float)\n",
    "    \n",
    "    Parameters:\n",
    "        allocation_sites_csv (str): Path to allocation_sites.csv\n",
    "    \n",
    "    Returns:\n",
    "        list: Sorted list of allocation sites.\n",
    "    \"\"\"\n",
    "    allocation_sites = []\n",
    "    with open(allocation_sites_csv, 'r', newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            start_hex = row['start'].strip()\n",
    "            size_str = row['size'].strip()\n",
    "            stack_trace = row['stack_trace'].strip()\n",
    "            \n",
    "            start = hex_to_int(start_hex)\n",
    "            if start is None:\n",
    "                continue  # Skip invalid start addresses\n",
    "            \n",
    "            try:\n",
    "                size = int(size_str)\n",
    "            except ValueError:\n",
    "                print(f\"Invalid size '{size_str}' for start address {start_hex}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            end = start + size\n",
    "            allocation_sites.append({\n",
    "                'start': start,\n",
    "                'end': end,\n",
    "                'size': size,\n",
    "                'stack_trace': stack_trace,\n",
    "                'total_stores': 0,\n",
    "                'zero_values': 0,\n",
    "                'max_value': None,\n",
    "                'min_value': None\n",
    "            })\n",
    "    \n",
    "    # Sort allocation sites by start address\n",
    "    allocation_sites.sort(key=lambda x: x['start'])\n",
    "    return allocation_sites\n",
    "\n",
    "def find_allocation_site(allocation_sites, address):\n",
    "    \"\"\"\n",
    "    Find the allocation site that contains the given address using binary search.\n",
    "    \n",
    "    Parameters:\n",
    "        allocation_sites (list): Sorted list of allocation sites.\n",
    "        address (int): The address to find.\n",
    "    \n",
    "    Returns:\n",
    "        dict or None: The allocation site dictionary if found, else None.\n",
    "    \"\"\"\n",
    "    # List of start addresses for binary search\n",
    "    starts = [site['start'] for site in allocation_sites]\n",
    "    index = bisect.bisect_right(starts, address) - 1\n",
    "    if index >= 0 and allocation_sites[index]['start'] <= address < allocation_sites[index]['end']:\n",
    "        return allocation_sites[index]\n",
    "    return None\n",
    "\n",
    "def analyze_allocation_sites_and_stores(stores_csv, allocation_sites_csv, output_csv):\n",
    "    \"\"\"\n",
    "    Analyze stores and allocation sites, computing required statistics.\n",
    "    \n",
    "    Parameters:\n",
    "        stores_csv (str): Path to stores.csv\n",
    "        allocation_sites_csv (str): Path to allocation_sites.csv\n",
    "        output_csv (str): Path to output CSV file\n",
    "    \"\"\"\n",
    "    print(\"Loading allocation sites...\")\n",
    "    allocation_sites = load_allocation_sites(allocation_sites_csv)\n",
    "    if not allocation_sites:\n",
    "        print(\"No valid allocation sites found. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Total allocation sites loaded: {len(allocation_sites)}\")\n",
    "    \n",
    "    # Prepare for binary search by ensuring allocation_sites is sorted\n",
    "    allocation_sites.sort(key=lambda x: x['start'])\n",
    "    \n",
    "    # Count total lines in stores.csv for tqdm\n",
    "    print(\"Counting total lines in stores.csv for progress tracking...\")\n",
    "    with open(stores_csv, 'r', newline='', encoding='utf-8') as f:\n",
    "        total_lines = sum(1 for _ in f)\n",
    "    \n",
    "    print(\"Processing stores.csv...\")\n",
    "    with open(stores_csv, 'r', newline='', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader, None)  # Skip header\n",
    "        if header is None:\n",
    "            print(\"stores.csv is empty. Exiting.\")\n",
    "            return\n",
    "        \n",
    "        # Determine the delimiter based on the header\n",
    "        delimiter = ',' if ',' in header[0] else ' '\n",
    "        \n",
    "        # Reset the file pointer to start processing\n",
    "        f.seek(0)\n",
    "        next(reader)  # Skip header again\n",
    "        \n",
    "        # Initialize tqdm with total lines minus header\n",
    "        for line in tqdm(reader, total=total_lines - 1, desc=\"Processing stores\", unit=\"store\"):\n",
    "            if not line:\n",
    "                continue  # Skip empty lines\n",
    "            \n",
    "            # Handle different delimiters\n",
    "            if delimiter == ',':\n",
    "                if len(line) < 2:\n",
    "                    print(f\"Malformed line (expected 2 columns): {line}\")\n",
    "                    continue\n",
    "                address_hex, value_hex = line[0].strip(), line[1].strip()\n",
    "            else:\n",
    "                if len(line) < 2:\n",
    "                    print(f\"Malformed line (expected 2 columns): {line}\")\n",
    "                    continue\n",
    "                address_hex, value_hex = line[0].strip(), line[1].strip()\n",
    "            \n",
    "            # Convert address to integer\n",
    "            address = hex_to_int(address_hex)\n",
    "            if address is None:\n",
    "                continue  # Skip invalid addresses\n",
    "            \n",
    "            # Convert value to double\n",
    "            value = hex_to_double(value_hex)\n",
    "            if value is None:\n",
    "                continue  # Skip invalid value conversions\n",
    "            \n",
    "            # Find the corresponding allocation site\n",
    "            site = find_allocation_site(allocation_sites, address)\n",
    "            if site:\n",
    "                # Update statistics\n",
    "                site['total_stores'] += 1\n",
    "                if value == 0.0:\n",
    "                    site['zero_values'] += 1\n",
    "                if (site['max_value'] is None) or (value > site['max_value']):\n",
    "                    site['max_value'] = value\n",
    "                if (site['min_value'] is None) or (value < site['min_value']):\n",
    "                    site['min_value'] = value\n",
    "            # Else: Address does not belong to any allocation site; ignore\n",
    "    \n",
    "    print(\"Writing analysis results to CSV...\")\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as f:\n",
    "        fieldnames = ['start', 'size', 'total_stores', 'zero_values', 'max_value', 'min_value', 'stack_trace']\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for site in allocation_sites:\n",
    "            writer.writerow({\n",
    "                'start': hex(site['start']),\n",
    "                'size': site['size'],\n",
    "                'total_stores': site['total_stores'],\n",
    "                'zero_values': site['zero_values'],\n",
    "                'max_value': site['max_value'] if site['max_value'] is not None else '',\n",
    "                'min_value': site['min_value'] if site['min_value'] is not None else '',\n",
    "                'stack_trace': site['stack_trace']\n",
    "            })\n",
    "    \n",
    "    print(f\"Analysis complete. Results saved to {output_csv}.\")\n",
    "\n",
    "analyze_allocation_sites_and_stores(\n",
    "    stores_csv='stores.csv',\n",
    "    allocation_sites_csv='allocation_sites.csv',\n",
    "    output_csv='allocation_analysis.csv'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
