{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a3550b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines: 100%|██████████| 622945/622945 [00:00<00:00, 976106.61line/s] \n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_memlog_in_chunks(file_path):\n",
    "    stores_file = open('stores.csv', 'w', newline='')\n",
    "    allocation_sites_file = open('allocation_sites.csv', 'w', newline='')\n",
    "\n",
    "    stores_writer = csv.writer(stores_file)\n",
    "    allocation_sites_writer = csv.writer(allocation_sites_file)\n",
    "\n",
    "    # Write header for the CSV files\n",
    "    stores_writer.writerow(['address', 'value'])\n",
    "    allocation_sites_writer.writerow(['start', 'size', 'stack_trace'])\n",
    "\n",
    "    store_started = False\n",
    "    allocation_started = False\n",
    "    allocation_sites = []\n",
    "    stack_trace = []\n",
    "\n",
    "    # Open the file and count the total number of lines for tqdm\n",
    "    with open(file_path, 'r') as f:\n",
    "        total_lines = sum(1 for line in f)  # Count total lines in the file\n",
    "        f.seek(0)  # Rewind the file to start processing\n",
    "\n",
    "        # Create a tqdm progress bar for line processing\n",
    "        for line in tqdm(f, total=total_lines, desc=\"Processing lines\", unit=\"line\"):\n",
    "            # Skip lines before \"Parent PID\" and the following line\n",
    "            if 'Parent PID' in line:\n",
    "                store_started = True\n",
    "                continue\n",
    "            elif store_started and line.strip() == '':\n",
    "                continue\n",
    "\n",
    "            # Process store lines\n",
    "            if store_started and not allocation_started:\n",
    "                # Ignore the line after the line containing 'Parent PID'\n",
    "                if len(line.strip().split()) == 1:\n",
    "                    continue\n",
    "\n",
    "                # Look for the \"=== Allocation sites ===\" line\n",
    "                if line.strip() == '=== Allocation sites ===':\n",
    "                    allocation_started = True\n",
    "                    continue\n",
    "\n",
    "                # Process store lines: <address> <value>\n",
    "                if line.strip():\n",
    "                    address, value = line.split()\n",
    "                    stores_writer.writerow([address, value])\n",
    "\n",
    "            # Process allocation site lines\n",
    "            if allocation_started:\n",
    "                if line.strip():\n",
    "                    if line.startswith('Start'):\n",
    "                        # Capture the start and size from the allocation site line\n",
    "                        start, size = line.split(',')[0].split()[1], line.split(',')[1].split()[1]\n",
    "                        # If there's already a previous allocation site, write it before starting a new one\n",
    "                        if allocation_sites:\n",
    "                            allocation_sites_writer.writerow([allocation_sites[0], allocation_sites[1], ' '.join(allocation_sites[2])])\n",
    "                        # Start a new allocation site\n",
    "                        allocation_sites = [start, size, []]\n",
    "                    else:\n",
    "                        # Add stack trace line for the current allocation site\n",
    "                        allocation_sites[2].append(line.strip())\n",
    "\n",
    "    # After finishing the file, write any remaining allocation site\n",
    "    if allocation_sites:\n",
    "        allocation_sites_writer.writerow([allocation_sites[0], allocation_sites[1], ' '.join(allocation_sites[2])])\n",
    "\n",
    "    # Close CSV files\n",
    "    stores_file.close()\n",
    "    allocation_sites_file.close()\n",
    "\n",
    "# Example usage\n",
    "process_memlog_in_chunks('memlog.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6b2294d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading allocation sites...\n",
      "Total allocation sites loaded: 2243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing stores: 607447store [00:31, 19128.45store/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing analysis results to CSV...\n",
      "Writing stores to separate allocation site files...\n",
      "Analysis complete. Files saved to allocation_site_stores.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from tqdm import tqdm\n",
    "import bisect\n",
    "import struct\n",
    "import os\n",
    "\n",
    "def hex_to_double(hex_str):\n",
    "    try:\n",
    "        hex_str = hex_str.lower().replace('0x', '').zfill(16)\n",
    "        byte_data = bytes.fromhex(hex_str)\n",
    "        return struct.unpack('>d', byte_data)[0]\n",
    "    except (ValueError, struct.error) as e:\n",
    "        print(f\"Error converting hex to double for '{hex_str}': {e}\")\n",
    "        return None\n",
    "\n",
    "def hex_to_int(hex_str):\n",
    "    try:\n",
    "        return int(hex_str, 16)\n",
    "    except ValueError:\n",
    "        print(f\"Invalid hexadecimal address: {hex_str}\")\n",
    "        return None\n",
    "\n",
    "def load_allocation_sites(allocation_sites_csv):\n",
    "    allocation_sites = []\n",
    "    with open(allocation_sites_csv, 'r', newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            start_hex = row['start'].strip()\n",
    "            start = hex_to_int(start_hex)\n",
    "            size = int(row['size'].strip()) if row['size'].strip().isdigit() else None\n",
    "            if start is None or size is None:\n",
    "                continue\n",
    "            allocation_sites.append({\n",
    "                'start_hex': start_hex,\n",
    "                'start': start,\n",
    "                'end': start + size,\n",
    "                'size': size,\n",
    "                'stack_trace': row['stack_trace'].strip(),\n",
    "                'total_stores': 0,\n",
    "                'zero_values': 0,\n",
    "                'max_value': None,\n",
    "                'min_value': None,\n",
    "                'stores': []\n",
    "            })\n",
    "    allocation_sites.sort(key=lambda x: x['start_hex'])\n",
    "    return allocation_sites\n",
    "\n",
    "def find_allocation_site(allocation_sites, address):\n",
    "    starts = [site['start'] for site in allocation_sites]\n",
    "    index = bisect.bisect_right(starts, address) - 1\n",
    "    if index >= 0 and allocation_sites[index]['start'] <= address < allocation_sites[index]['end']:\n",
    "        return allocation_sites[index]\n",
    "    return None\n",
    "\n",
    "def analyze_allocation_sites_and_stores(stores_csv, allocation_sites_csv, output_csv, output_dir):\n",
    "    print(\"Loading allocation sites...\")\n",
    "    allocation_sites = load_allocation_sites(allocation_sites_csv)\n",
    "    if not allocation_sites:\n",
    "        print(\"No valid allocation sites found. Exiting.\")\n",
    "        return\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Total allocation sites loaded: {len(allocation_sites)}\")\n",
    "    \n",
    "    with open(stores_csv, 'r', newline='', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader, None)\n",
    "        if header is None:\n",
    "            print(\"stores.csv is empty. Exiting.\")\n",
    "            return\n",
    "        f.seek(0)\n",
    "        next(reader)\n",
    "        for line in tqdm(reader, desc=\"Processing stores\", unit=\"store\"):\n",
    "            if len(line) < 2:\n",
    "                continue\n",
    "            address_hex = line[0].strip()\n",
    "            address = hex_to_int(address_hex)\n",
    "            value_hex = line[1].strip()\n",
    "            value = hex_to_double(value_hex)\n",
    "            if address is None or value is None:\n",
    "                continue\n",
    "            site = find_allocation_site(allocation_sites, address)\n",
    "            if site:\n",
    "                site['total_stores'] += 1\n",
    "                site['stores'].append({\n",
    "                    'address': address_hex, \n",
    "                    'value': value\n",
    "                })\n",
    "                if value == 0.0:\n",
    "                    site['zero_values'] += 1\n",
    "                if (site['max_value'] is None) or (value > site['max_value']):\n",
    "                    site['max_value'] = value\n",
    "                if (site['min_value'] is None) or (value < site['min_value']):\n",
    "                    site['min_value'] = value\n",
    "\n",
    "    print(\"Writing analysis results to CSV...\")\n",
    "    allocation_sites.sort(key=lambda x: x['size'])\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as f:\n",
    "        fieldnames = ['start_hex', 'start', 'end', 'size', 'total_stores', 'zero_values', 'max_value', 'min_value', 'stack_trace']\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for site in allocation_sites:\n",
    "            writer.writerow({\n",
    "                'start_hex': site['start_hex'],\n",
    "                'start': site['start'],\n",
    "                'end': site['end'],\n",
    "                'size': site['size'],\n",
    "                'total_stores': site['total_stores'],\n",
    "                'zero_values': site['zero_values'],\n",
    "                'max_value': site['max_value'] if site['max_value'] is not None else '',\n",
    "                'min_value': site['min_value'] if site['min_value'] is not None else '',\n",
    "                'stack_trace': site['stack_trace']\n",
    "            })\n",
    "    \n",
    "    print(\"Writing stores to separate allocation site files...\")\n",
    "    for site in allocation_sites:\n",
    "        filename = site['start_hex'] + \".csv\"\n",
    "        file = os.path.join(output_dir, filename)\n",
    "        with open(file, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=['address', 'value'])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(site['stores'])\n",
    "    print(f\"Analysis complete. Files saved to {output_dir}.\")\n",
    "\n",
    "analyze_allocation_sites_and_stores(\n",
    "    stores_csv='stores.csv',\n",
    "    allocation_sites_csv='allocation_sites.csv',\n",
    "    output_csv='allocation_analysis.csv',\n",
    "    output_dir='allocation_site_stores'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
